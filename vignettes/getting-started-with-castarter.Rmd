---
title: "Getting started with `castarter`"
author: "Giorgio Comai"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting started with `castarter`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Books dedicated to content analysis typically assume that the researcher has already created, has access or may buy access to a structured dataset. They may include sections on sampling (Krippendorff 2004; Riffe, Lacy, and Fico 2005), but they do not debate explicitly how new datasets can be built. Commercial software packages generally share the same expectation. In the R ecosystem, there are a number of packages that can be used to access existing datasets (e.g. tm.plugin.lexisnexis, manifestoR) or import into R textual content from social media through their APIs (e.g. twitteR). However, there is no package dedicated to getting into R the textual contents of regular websites and extracting key metadata (date and title) in order to populate a corpus that can be analysed in R or with other software packages. 'castarter - content analysis starter toolkit for R' aims to accomplish just that, offering to moderately incompetent users the opportunity to extract textual contents from websites and prepare them for content analysis. It allows to export the datasets in a number of standard formats for further processing and facilitates basic word frequency analysis in R.

For further debate on the usefulness of a structured approach to analysing web contents in the context of area studies, and for some practical examples of how `castarter` has been used, see:

```{r eval=FALSE}
citation("castarter")
```

> Comai, Giorgio (2017). Quantitative Analysis of Web Content in Support of Qualitative Research. Examples from the Study of Post-Soviet De Facto States, *Studies of Transition States and Societies*, 9(1), 14-34.
  http://publications.tlu.ee/index.php/stss/article/view/346/446.

## Installation

`castarter` can easily be installed from GitHub with `devtools`:

```{r eval=FALSE}
#install.packages("devtools")
devtools::install_github("giocomai/castarter")
library("castarter")
```

```{r eval=TRUE, include=FALSE}
library("castarter")
```

## Preliminary note

`castarter` targets specifically relatively inexperienced users. Many of the functions it offers will look trivial to expert R users. Yet, even experienced users will benefit of some of `castarter`'s convenience functions, including its ability to download and parse pages systematically (and continue download processes if it has been interrupted).

## Setting up the environment

`castarter` facilitates downloading and extracting textual contents from a website, or a given section of a website. `castarter` can be used to analyse a single website, or more websites as part of a project, facilitating comparison among cases. In order to smoothen replication and prevent data losses, by default `castarter` stores a copy of downloaded web pages in html format. To do so, it includes a function that creates the relevant folder structure, and another function that facilitates archiving the html files in compressed format.
In `castarter` every dataset is expected to be extracted from a website, and each website is expected to be part of a project. This is useful to give a consistent way of storing the materials gathered and to facilitate comparison among cases, but it does not imply additional limitations: it is possible to have projects composed of a single website, and it is possible to make comparisons among websites that are part of different projects.

As an example, this vignette will demonstrate how to extract press releases published by the Kremlin. When starting a new `castarter` project, the first step is usally that of defining the name of the project and the name of website. In this case, the project will be called "Presidents", assuming other websites to be analysed later may be of presidents of other countries.

```{r}
SetCastarter(project = "Presidents", website = "Kremlin_en")
```

This stores the names of project and website as options that can be retrieved by all `castarter` functions automatically, without the need to inputting them each time a function requires to save or load files.

Then, it is time to create the folder structure where all outputs will be saved:

```{r eval=FALSE}
CreateFolders()
```

This creates the following folders in the current working directory:

-   Presidents
    -   Kremlin_en
        -   Archives
        -   Dataset
        -   Html
        -   IndexHtml
        -   Logs
        -   Outputs
        -   Txt

Notice that there is no need to provide names of project and website to the function `CreateFolders()`, since they are retrieved from the previously set options.

## Download index pages

From the Kremlin's website, as in many other websites, it is easy to understand the structure of the archive: it is composed by `http://en.kremlin.ru/events/president/news/page/` plus a number. By clicking on the "previous" link at the bottom of the page, as it is customary, the user is given the possibility to see older press released. In `castarter`, it is possible to get the links to all the pages we would see by clicking subsequent times on the 'previous page' link, with the following command function:

```{r}
indexLinks <- CreateLinks(linkFirstChunk = "http://en.kremlin.ru/events/president/news/page/",
                          startPage = 1,
                          endPage = 1100)
head(indexLinks)
```

N.B. Another frequently found way for websites to provide access to their archives is by creating pages with dates directly in their URL. If, for example, a website offers its contents in the form of <http://www.example.com/archive/2015-10-22>, then it would be possible to generate the links for all the dates, say, between January 2012 and December 2015, with the following parameters: `CreateLinks(linkFirstChunk = "http://www.example.com/", startDate = "2012-01-01", endDate = "2015-12-31", dateSeparator = "-")`

This command creates a vector (`indexLinks`) including direct links to the index pages. 

It is now necessary to download these index pages. The following command downloads the relevant index pages and saves them in html format in the `/Presidents/Kremlin_en/IndexHtml/` folder.

```{r eval=FALSE}
DownloadContents(links = indexLinks, type = "index")
```

If the process is interrupted for any reason, it is possible simply to run again the same function, which will check which files have already been downloaded, and will download the missing ones. Sometimes, due to a number of reasons, one or a few pages may not download correctly. It is usually appropriate to run the following function, which will re-download files that are too small to contain meaningful contents (if all pages have been downloaded correctly, the following will not do anything).

```{r eval=FALSE}
DownloadContents(links = indexLinks, type = "index", missingPages = FALSE)
```

## Extracting links

Now that we have the index pages, we need to extract direct links to the individual press releases. There are various ways to do this, but the easiest approach is looking at the URLs of individual articles, and see if there is a pattern (this is very often the case in modern websites). Hovering over the titles of an index page, it is easy to see the links to indivudal news items. In this case, we see that the URL to each news item includes in the URL the following string: "/news/en/news-room/content/". We use this to extract relevant links, and discard all links to other pages or sections of the website scattered around the page that we are not interested in. The following command extracts links to individual articles, and tries to guess the title of the article.

---

[in progress]

[See full script to create a new dataset](https://github.com/giocomai/castarter/blob/master/inst/extdata/R-Script-examples/Kremlin_en.R). 

See an [online interactive interface](https://giocomai.shinyapps.io/Kremlin_en/) allowing to explore the dataset, created with the `castarter::CreateShinyApp()` function. 
